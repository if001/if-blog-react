{"componentChunkName":"component---src-templates-tag-js","path":"/tags/構文解析/","webpackCompilationHash":"01eaf5e6ec7e5dd6e10a","result":{"data":{"site":{"siteMetadata":{"title":"アンドロイドは推理小説を書くか?","author":"いふ","labels":[{"tag":"react","tech":"React","name":"DiReact","size":17,"color":"black"},{"tag":"nodejs","tech":"Node.js","name":"DiNodejsSmall","size":17,"color":"green"},{"tag":"git","tech":"Git","name":"DiGit","size":17,"color":"black"},{"tag":"javascript","tech":"JavaScript","name":"DiJsBadge","size":17,"color":"black"},{"tag":"css","tech":"CSS","name":"DiCss3Full","size":17,"color":"teal"},{"tag":"python","tech":"Python","name":"DiPython","size":17,"color":"deepskyblue"},{"tag":"ruby","tech":"Ruby","name":"DiRuby","size":17,"color":"crimson"},{"tag":"java","tech":"Java","name":"FaJava","size":17,"color":"red"},{"tag":"angular","tech":"Angular","name":"DiAngularSimple","size":17,"color":"red"},{"tag":"html","tech":"HTML","name":"FaHtml5","size":17,"color":"darkorange"},{"tag":"php","tech":"php","name":"DiPhp","size":17,"color":"violet"},{"tag":"mongodb","tech":"MongoDB","name":"DiMongodb","size":17,"color":"green"},{"tag":"vscode","tech":"VS Code","name":"DiVisualstudio","size":17,"color":"deepskyblue"},{"tag":"go","tech":"go","name":"DiGo","size":17,"color":"black"},{"tag":"golang","tech":"Golang","name":"DiGo","size":17,"color":"black"},{"tag":"読書","tech":"読書","name":"FaBookOpen","size":17,"color":"blue"},{"tag":"読了","tech":"読了","name":"FaBook","size":17,"color":"green"},{"tag":"hugo","tech":"Hugo","name":"FaServer","size":17,"color":"pink"},{"tag":"docker","tech":"Docker","name":"DiDocker","size":17,"color":"blue"},{"tag":"aws","tech":"Aws","name":"DiAws","size":17,"color":"orange"},{"tag":"nlp","tech":"NLP","name":"FaLanguage","size":17,"color":"black"},{"tag":"firebase","tech":"FireBase","name":"DiGoogleCloudPlatform","size":17,"color":"blue"},{"tag":"deeplearning","tech":"DeepLearning","name":"FaBrain","size":17,"color":"blue"},{"tag":"poem","tech":"poem","name":"FaPenFancy","size":17,"color":"yellow"},{"tag":"rust","tech":"rust","name":"DiRust","size":17,"color":"black"},{"tag":"tex","tech":"tex","name":"FaTextHeight","size":17,"color":"teal"}]}},"allMarkdownRemark":{"totalCount":1,"edges":[{"node":{"excerpt":"はじめに 自然言語処理シリーズの構文解析を読んでいきます。  全体の概要把握:1時間\n中身の細かいとこ：3時間\nという感じで読み進めて行こうと思います。 概要 構文解析を用いることで、単語の並びの背後にある文法的な構造を明らかにすることができる。構文解析を学ぶことで、自然言語処理で用いられる様々な先人の知恵を学習できる。 この本では以下のような構成となっている。 1章、はじめに…","html":"<h2 id=\"はじめに\"><a href=\"#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB\" aria-label=\"はじめに permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>はじめに</h2>\n<p>自然言語処理シリーズの構文解析を読んでいきます。</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 336px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/if-blog-react/static/0a76326d12676389e9c6b3d655b8bc0e/da001/parse_front_cover.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 148.51190476190476%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAeABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAIBAwQF/8QAFgEBAQEAAAAAAAAAAAAAAAAAAQAC/9oADAMBAAIQAxAAAAHuJasMBK06VcySGv/EABoQAQACAwEAAAAAAAAAAAAAAAECEAAREiH/2gAIAQEAAQUCX3qnBqRsHmVar//EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAEDAQE/AYk//8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQIBAT8BKf/EABoQAAICAwAAAAAAAAAAAAAAAAEgADERQWH/2gAIAQEABj8CAm6zTcX/xAAbEAACAgMBAAAAAAAAAAAAAAAAARExECFBYf/aAAgBAQABPyGLYl+Sa2DwpBbbgmTsDIHY5hq7WP/aAAwDAQACAAMAAAAQy848/8QAFxEBAQEBAAAAAAAAAAAAAAAAAREQMf/aAAgBAwEBPxBS5dp3P//EABYRAQEBAAAAAAAAAAAAAAAAAAEQEf/aAAgBAgEBPxCGDGf/xAAcEAEAAgMBAQEAAAAAAAAAAAABABEhMUFRYXH/2gAIAQEAAT8QpqltIxg68hRaRxWvP35DIXzyLsi6S4SAo6pzAATTMPYpvHfkCeAL7DTFTZFxCxsYz//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"parse_front_cover\"\n        title=\"parse_front_cover\"\n        src=\"/if-blog-react/static/0a76326d12676389e9c6b3d655b8bc0e/da001/parse_front_cover.jpg\"\n        srcset=\"/if-blog-react/static/0a76326d12676389e9c6b3d655b8bc0e/5fb09/parse_front_cover.jpg 100w,\n/if-blog-react/static/0a76326d12676389e9c6b3d655b8bc0e/f544b/parse_front_cover.jpg 200w,\n/if-blog-react/static/0a76326d12676389e9c6b3d655b8bc0e/da001/parse_front_cover.jpg 336w\"\n        sizes=\"(max-width: 336px) 100vw, 336px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>全体の概要把握:1時間\n中身の細かいとこ：3時間\nという感じで読み進めて行こうと思います。</p>\n<h2 id=\"概要\"><a href=\"#%E6%A6%82%E8%A6%81\" aria-label=\"概要 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>概要</h2>\n<p>構文解析を用いることで、単語の並びの背後にある文法的な構造を明らかにすることができる。構文解析を学ぶことで、自然言語処理で用いられる様々な先人の知恵を学習できる。</p>\n<p>この本では以下のような構成となっている。</p>\n<ul>\n<li>1章、はじめに</li>\n<li>2章、品詞タグ付けのための手法と、機械学習の基礎的な事項について</li>\n<li>3章、句構造解析について</li>\n<li>4章、依存構造解析</li>\n<li>5章、文法理論、深い構文解析</li>\n<li>6章、構文解析の応用例</li>\n<li>7章、構文解析ツールの紹介</li>\n<li>8章、モデルやアルゴリズムの学習用・評価用データに用いられるツリーバンクの紹介</li>\n</ul>\n<p>以下、各章の概要まとめです。</p>\n<h2 id=\"2章：品詞解析と機械学習\"><a href=\"#2%E7%AB%A0%EF%BC%9A%E5%93%81%E8%A9%9E%E8%A7%A3%E6%9E%90%E3%81%A8%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\" aria-label=\"2章：品詞解析と機械学習 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2章：品詞解析と機械学習</h2>\n<p>品詞解析のためのさまざまな技術の解説し、その基盤となる機械学習の考え方と代表的なモデルを紹介する。</p>\n<p>品詞タグ付け：与えられた文章の各単語の品詞を判定し、品詞情報を付与する処理\n品詞タガー：品詞タグ付けを行うプログラム\nルールベースの手法：shoudの後には動詞がくると決めうちでタグ付けをする手法\n素性: 品詞判定の手がかりとして利用する情報</p>\n<h4 id=\"隠れマルコフモデル\"><a href=\"#%E9%9A%A0%E3%82%8C%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E3%83%A2%E3%83%87%E3%83%AB\" aria-label=\"隠れマルコフモデル permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>隠れマルコフモデル</h4>\n<p>機械学習に基づく品詞タグ付け手法の中で基本的なもの。\n単純な計算では、文長に対し計算量が指数関数的に増加する問題がある。</p>\n<h4 id=\"viterbiアルゴリズム\"><a href=\"#viterbi%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0\" aria-label=\"viterbiアルゴリズム permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Viterbiアルゴリズム</h4>\n<p>計算量増加の問題を解決。動的計画法の1種。\nアンダーフローの問題がある、この問題に対し、対数をとっても良いが計算が遅くなるというデメリットもある。</p>\n<h4 id=\"最大エントロピーモデル\"><a href=\"#%E6%9C%80%E5%A4%A7%E3%82%A8%E3%83%B3%E3%83%88%E3%83%AD%E3%83%94%E3%83%BC%E3%83%A2%E3%83%87%E3%83%AB\" aria-label=\"最大エントロピーモデル permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>最大エントロピーモデル</h4>\n<p>最大エントロピーモデルは、品詞判定に役立つ手がかりを素性として利用し予測できるアルゴリズムの一種。品詞の前後のつながりを考慮せずに予測するというモデル。\n計算コストは少ないが、素性を柔軟に設計できないため精度が低いという問題点がある。\n自然言語処理では、実装が簡単なことからSGDがよく用いられる。学習データの数が多い場合には、短時間で最適化を行うことができる。</p>\n<h4 id=\"最大エントロピーマルコフモデル\"><a href=\"#%E6%9C%80%E5%A4%A7%E3%82%A8%E3%83%B3%E3%83%88%E3%83%AD%E3%83%94%E3%83%BC%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E3%83%A2%E3%83%87%E3%83%AB\" aria-label=\"最大エントロピーマルコフモデル permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>最大エントロピーマルコフモデル</h4>\n<p>最大エントロピーモデルに、品詞のつながりを考慮させ正確な予測を行うことできるように改良されたモデル。\n先行する単語の品詞に関数情報を素性として利用するできるが、最初にタグ付けを間違えると、その誤りによって別の誤りが引き起こされてしまう問題がある。</p>\n<h4 id=\"条件付き確率場crf\"><a href=\"#%E6%9D%A1%E4%BB%B6%E4%BB%98%E3%81%8D%E7%A2%BA%E7%8E%87%E5%A0%B4crf\" aria-label=\"条件付き確率場crf permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>条件付き確率場(CRF)</h4>\n<p>各単語の品詞を個別に予測するのではなく、文全体の品詞列全体を一度に予測しようとするアプローチに基づく代表的な確率モデル。</p>\n<h4 id=\"構造化パーセプトロン\"><a href=\"#%E6%A7%8B%E9%80%A0%E5%8C%96%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3\" aria-label=\"構造化パーセプトロン permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>構造化パーセプトロン</h4>\n<p>CRFでは、登場する品詞列すべてに対し確率を求めるが、もっとも正解である確率の高い品詞列さえ得られれば良いという状況もある。そのような状況では、構造化パーセプトロンが役にたつ。動的計画法を用いて品詞タグ付けを行う。</p>\n<h4 id=\"ビーム探索\"><a href=\"#%E3%83%93%E3%83%BC%E3%83%A0%E6%8E%A2%E7%B4%A2\" aria-label=\"ビーム探索 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ビーム探索</h4>\n<p>構造化パーセプトロンでは動的計画法を用いて品詞タグ付けを行ったが、素性が局所的な場合には、動的計画法が使えない。そこで、非局所的な様々な素性を利用するためによく用いられるのがビーム探索である。似たような手法として、Max Violationがある。</p>\n<h4 id=\"生コーパスを利用した学習\"><a href=\"#%E7%94%9F%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%9F%E5%AD%A6%E7%BF%92\" aria-label=\"生コーパスを利用した学習 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>生コーパスを利用した学習</h4>\n<p>これまでの学習は、コーパスを前提にしたものだった。しかしコーパスの構築には膨大な時間がかかる。与えられた文章のみで学習する手法を、半教師あり学習と呼ぶ。</p>\n<h4 id=\"自己学習\"><a href=\"#%E8%87%AA%E5%B7%B1%E5%AD%A6%E7%BF%92\" aria-label=\"自己学習 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>自己学習</h4>\n<p>生コーパスを用いる学習に自己学習と呼ばれる方法がある。\nこれは、CRFや構造化パーセプトロンでは精度向上に効果がないが、隠れマルコフモデルのような生成モデルでは大きな精度向上を得ることができる。これは、生成モデルの場合、EMアルゴリズムの1ステップに対応しているからである。隠れマルコフモデルで自己学習を行う場合、Baum-Welchアルゴリズムを用いる。</p>\n<h2 id=\"3章：句構造解析\"><a href=\"#3%E7%AB%A0%EF%BC%9A%E5%8F%A5%E6%A7%8B%E9%80%A0%E8%A7%A3%E6%9E%90\" aria-label=\"3章：句構造解析 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3章：句構造解析</h2>\n<p>構文解析の表現方法の1つである句構造と、それに基づく構文解析の手法について説明する。</p>\n<h4 id=\"句構造\"><a href=\"#%E5%8F%A5%E6%A7%8B%E9%80%A0\" aria-label=\"句構造 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>句構造</h4>\n<p>文中の句同士の包含関係を階層的にまとめあげることで、その構造を明らかにする。\n適切な句構造を得るための問題を2つに分けると、与えられた文に対して文法上可能な全ての句構造を計算することと、それらの中から最も適切な句構造を選択することとなる。</p>\n<h4 id=\"文脈自由文法\"><a href=\"#%E6%96%87%E8%84%88%E8%87%AA%E7%94%B1%E6%96%87%E6%B3%95\" aria-label=\"文脈自由文法 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>文脈自由文法</h4>\n<p>文の句構造を表現するための、最も基本的な文法の一つ。\n文脈自由文法のためのボトムアップな構文解析手法の一つであるCKY法と、任意の文脈自由文法を用いてトップダウンに構文解析を行うことが可能なEarly法がある。</p>\n<h4 id=\"確率文脈自由文法pcfg\"><a href=\"#%E7%A2%BA%E7%8E%87%E6%96%87%E8%84%88%E8%87%AA%E7%94%B1%E6%96%87%E6%B3%95pcfg\" aria-label=\"確率文脈自由文法pcfg permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>確率文脈自由文法(PCFG)</h4>\n<p>句構造を列挙した上で、最も確からしい句構造を選択する枠組みの1つ</p>\n<h4 id=\"確率文脈自由文法pcfgの拡張\"><a href=\"#%E7%A2%BA%E7%8E%87%E6%96%87%E8%84%88%E8%87%AA%E7%94%B1%E6%96%87%E6%B3%95pcfg%E3%81%AE%E6%8B%A1%E5%BC%B5\" aria-label=\"確率文脈自由文法pcfgの拡張 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>確率文脈自由文法(PCFG)の拡張</h4>\n<p>PCFGを拡張した、Collins Parserの手法について解説\n生成的な確率モデルを注意深く設計することで、正しい構文木にたいして大きな確率がわりあてられるようにする。</p>\n<h4 id=\"識別モデルによる際順位付け\"><a href=\"#%E8%AD%98%E5%88%A5%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AB%E3%82%88%E3%82%8B%E9%9A%9B%E9%A0%86%E4%BD%8D%E4%BB%98%E3%81%91\" aria-label=\"識別モデルによる際順位付け permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>識別モデルによる際順位付け</h4>\n<p>正しい構文木とそうでない構文木を区別する特徴はいくつかあるが、Collins Parserでは限られたものしか考慮することができない。</p>\n<h4 id=\"評価法\"><a href=\"#%E8%A9%95%E4%BE%A1%E6%B3%95\" aria-label=\"評価法 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>評価法</h4>\n<p>句構造解析の精度の評価には、構文木を構成する句の適合率(precision)と再現率(recall)がよく用いられる。</p>\n<h2 id=\"4章依存構造解析\"><a href=\"#4%E7%AB%A0%E4%BE%9D%E5%AD%98%E6%A7%8B%E9%80%A0%E8%A7%A3%E6%9E%90\" aria-label=\"4章依存構造解析 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4章:依存構造解析</h2>\n<p>依存構造とは、文中の単語間の関係をグラフで表したものである。</p>\n<h4 id=\"cky法\"><a href=\"#cky%E6%B3%95\" aria-label=\"cky法 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CKY法</h4>\n<p>依存構造を句構造だと考え解析する。</p>\n<h4 id=\"eisner法\"><a href=\"#eisner%E6%B3%95\" aria-label=\"eisner法 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Eisner法</h4>\n<p>同じ出力を得るための解析プロセスが複数存在することを、擬似曖昧性と呼ぶ。\n依存構文解析において、擬似曖昧性が生じないようにCKY法を改良したものがEisner法である。</p>\n<h4 id=\"mst法\"><a href=\"#mst%E6%B3%95\" aria-label=\"mst法 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MST法</h4>\n<p>これまでの手法は、句構造解析のアルゴリズムを依存構造解析に応用したものであったが、依存構文解析に特有の手法として、最大全域木(MST)法を応用したものが知られている。\n最大全域木とは、エッジにスコアが与えられたグラフを入力として、全ノードを被覆する木(=全域木)のうち、スコアのわが最大となるものを求めるアルゴリズムである。</p>\n<h4 id=\"遷移型依存構造解析\"><a href=\"#%E9%81%B7%E7%A7%BB%E5%9E%8B%E4%BE%9D%E5%AD%98%E6%A7%8B%E9%80%A0%E8%A7%A3%E6%9E%90\" aria-label=\"遷移型依存構造解析 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>遷移型依存構造解析</h4>\n<p>句造像解析と同様のアルゴリズムを依存構造解析でも考えることができる。</p>\n<h4 id=\"日本語構文解析\"><a href=\"#%E6%97%A5%E6%9C%AC%E8%AA%9E%E6%A7%8B%E6%96%87%E8%A7%A3%E6%9E%90\" aria-label=\"日本語構文解析 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>日本語構文解析</h4>\n<p>p102(スキップ)</p>\n<h4 id=\"評価法-1\"><a href=\"#%E8%A9%95%E4%BE%A1%E6%B3%95-1\" aria-label=\"評価法 1 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>評価法</h4>\n<p>依存構造解析の評価には、ラベル付きかかり受け精度およびラベルなしかかり受け精度が用いられる。</p>\n<h2 id=\"5章：文法理論、深い構文解析\"><a href=\"#5%E7%AB%A0%EF%BC%9A%E6%96%87%E6%B3%95%E7%90%86%E8%AB%96%E3%80%81%E6%B7%B1%E3%81%84%E6%A7%8B%E6%96%87%E8%A7%A3%E6%9E%90\" aria-label=\"5章：文法理論、深い構文解析 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5章：文法理論、深い構文解析</h2>\n<p>3、4章で解説した、句構造・依存構造では明示されない意味的構造をも計算する、構文解析のことを、<strong>深い構文解析</strong>と呼ぶ。</p>\n<h4 id=\"組み合わせ範疇文法ccg\"><a href=\"#%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E7%AF%84%E7%96%87%E6%96%87%E6%B3%95ccg\" aria-label=\"組み合わせ範疇文法ccg permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>組み合わせ範疇文法(CCG)</h4>\n<p>組み合わせ範疇文法(CCG)とは、各単語にその文法機能を表すカテゴリを与え、そのカテゴリを組み合わせることで文の構造を計算する。</p>\n<h4 id=\"主辞駆動句構造文法hpsg\"><a href=\"#%E4%B8%BB%E8%BE%9E%E9%A7%86%E5%8B%95%E5%8F%A5%E6%A7%8B%E9%80%A0%E6%96%87%E6%B3%95hpsg\" aria-label=\"主辞駆動句構造文法hpsg permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>主辞駆動句構造文法(HPSG)</h4>\n<p>主辞駆動句構造文法(HPSG)とは、主辞(句の中で意味的もしくは文法的に中心的な役割を果たす語)が持つ文法機能を素性構造というデータ構造で表し、それに基づき文全体の構造を決定する文法理論である。素性構造では、C++の構造体やオブジェクト指向言語におけるクラスに似た形でデータを表す。</p>\n<h4 id=\"深い構文解析\"><a href=\"#%E6%B7%B1%E3%81%84%E6%A7%8B%E6%96%87%E8%A7%A3%E6%9E%90\" aria-label=\"深い構文解析 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>深い構文解析</h4>\n<p>CCGやHPSGのような文法理論を用いて、CFGより多くの情報をもたせた文法構造を解析する手法を深い文法構造と呼ぶ。</p>","id":"f9614d7a-0f59-52eb-b7ef-12443223616f","frontmatter":{"title":"自然言語処理シリーズの構文解析を読む（概要）","date":"2019-09-23","tags":["nlp","構文解析"]},"fields":{"slug":"/nlp/nlp_parse_overview-1/"}}}]}},"pageContext":{"isCreatedByStatefulCreatePages":false,"tag":"構文解析"}}}